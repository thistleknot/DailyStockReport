#I want it to work with CSV's to save expense on operations.
download=FALSE
#set to true to  install devtools
firstRun=FALSE

#constants, also referenced by getSymbols3.R
source("lists.R")
source("tech_ind.R")

source("TradingDates.R")
source("colSortAndFilter.R")

require(stringi)
require(reshape2)
require(zoo)
require(PerformanceAnalytics)
#filter
require(dplyr)
require(ismev)
require(data.table)
require(parallel)
require(tidyquant)
#require(psych)
require(Quandl)
require(curl)
#wget
library(HelpersMG)
#interpolate_TS
library(imputeTS)
#plot.acf
library(stats)
#CCF
library(tseries)
#coh
library(seewave)

library(forecast)
#acf2
library(astsa)
#list.cbind
library(rlist)
#for adjusted
library(quantmod)
#EMA
library(TTR)

library(arfima)

library(caret)

#impute
library(mice)

#streak_run
library(runner)

#mape that works on model
#library(modelr)

library(yardstick)

Quandl.api_key("QgfDPCzvVmkDub4QqjQs")

#Begin Functions

source("functions.R")

#End functions

if(download)
{
  wget("ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqtraded.txt")
  wget("ftp://ftp.nasdaqtrader.com/SymbolDirectory/mfundslist.txt")
}

#stocks <- rbindlist(dget(All3[[1]][[1]],keep.source = TRUE), use.names=TRUE, fill=TRUE, idcol="Symbol")
mfunds <- read.csv(file="200MFundsSymbols2Years.csv", header=TRUE,colClasses=c("character","Date","numeric","numeric","numeric","numeric","numeric","numeric"))
stocks <- read.csv(file="200NasdaqSymbols2Years.csv", header=TRUE,colClasses=c("character","Date","numeric","numeric","numeric","numeric","numeric","numeric"))
#mfunds <- rbindlist(dget(All3[[2]][[1]],keep.source = TRUE), use.names=TRUE, fill=TRUE, idcol="Symbol")

#check duplicates
listStocks <- sort(unique(stocks$Symbol))
listmfunds <- sort(unique(mfunds$Symbol))

FRED_factors_DF <- read.csv(file="FRED_factors.csv",header=TRUE)
listFRED_factors <- sort(unique(FRED_factors_DF$Symbol))
colnames(FRED_factors_DF) <- c("Symbol", "Date", "Price")
FRED_factors_DF$Date <- as.Date(as.character(FRED_factors_DF$Date))

etf_and_crypto_DF <- read.csv(file="etf_and_crypto.csv",header=TRUE)
colnames(etf_and_crypto_DF) <- c("Symbol", "Date", "Open", "High", "Low", "Close", "Volume", "Adjusted")
etf_and_crypto_DF$Date <- as.Date(as.character(etf_and_crypto_DF$Date))
etf_and_crypto_DF$Symbol <- as.character(etf_and_crypto_DF$Symbol)

temp <- etf_and_crypto_DF[which(etf_and_crypto_DF$Symbol=="ETH"),]$Symbol
temp <- matrix("Etherium", length(temp))
etf_and_crypto_DF[which(etf_and_crypto_DF$Symbol=="ETH"),]$Symbol <- c(temp)
etf_and_Crypto_list[which(etf_and_Crypto_list=="ETH")]="Etherium"

temp <- etf_and_crypto_DF[which(etf_and_crypto_DF$Symbol=="BTCUSD=X"),]$Symbol
temp <- matrix("BTCUSD.X", length(temp))
etf_and_crypto_DF[which(etf_and_crypto_DF$Symbol=="BTCUSD=X"),]$Symbol <- c(temp)
etf_and_Crypto_list[which(etf_and_Crypto_list=="BTCUSD=X")]="BTCUSD.X"

#listETF <- sort(unique(etf_and_crypto_DF$Symbol))

if(download)
{
  source("getSymbols3.R")
}

#https://stackoverflow.com/questions/4386154/how-to-find-the-highest-latest-and-lowest-earliest-date-r

#https://stackoverflow.com/questions/652136/how-can-i-remove-an-element-from-a-list
dups <- c(listStocks,listmfunds)[duplicated(c(listStocks,listmfunds))]

liststocksNoDups <- setdiff(listStocks,c(dups))

#mfunds[ which(mfunds$Symbol %in% c(dups)),] 
#                         & mydata$age > 65), ]
symbol_data_set <- rbind(mfunds,stocks[stocks$Symbol %in% liststocksNoDups,])

#unlist(lapply(symbol_data_set, class))

initial_first_date <- min(stocks$Date[1],mfunds$Date[1])
#test loop (moving window)
i=0
#for(i in 0:17)
#{

first.date <- initial_first_date + months(i)
last.date <- max(tail(stocks$Date,1),tail(mfunds$Date,1))

if(download)
{
  first.date <- Sys.Date()
  last.date <- Sys.Date() - 821
}
#last.date <- first.date + months(9)
FiveYearsBack = last.date-1826

#test <- Quandl.datatable("ZACKS/FC", ticker=c("AAPL"), end_date=last.date)
#help(Quandl)

#adjusted <- cbind(dates1,data.frame(adjusted))
#colnames(adjusted) <- c("Date","Open","High","Low","Close","Volume","Adjusted")
years <- seq(as.integer(extract_year((FiveYearsBack))):as.integer(extract_year(last.date)))+as.integer(extract_year(FiveYearsBack))-1

dates <- mclapply(years, function (x){
  TradingDates(x)
})

trading_dates <- data.frame(as.Date(unlist(dates)))[,,drop=FALSE]

#go 5 years back, but not in the future
trading_dates <- data.frame(trading_dates[trading_dates <= paste(last.date),])[,,drop=FALSE]

colnames(trading_dates) <- c("Date")
#https://stats.stackexchange.com/questions/220865/how-to-select-a-range-of-dates-in-r
filtered_trading_dates <- data.frame(trading_dates[trading_dates >= paste(first.date) & trading_dates <= paste(last.date),])[,,drop=FALSE]
colnames(filtered_trading_dates) <- c("Date")

#colnames(stocks)

#for beta calculations

indices_DF <- read.csv(file="indices.csv",header=T,colClasses = c("character","Date","numeric","numeric","numeric","numeric","numeric","numeric" ))
#change date to date class
indices_DF[,2] <- as.Date(as.character(indices_DF[,2]))
colnames(indices_DF) <- c("Symbol","Date","Open","High","Low","Close","Volume","Adjusted")
#indices <- group_split(indices_DF %>% group_by(Symbol))
#indices <- split(indices_DF, indices_DF$Symbol)

indices_pvtwNA <- reshape2::dcast(indices_DF, Date ~ Symbol,value.var='Adjusted',fun.aggregate = mean, fill=NULL)

#merge with trading days prior to return?
#lapply(indices_pvtwNA,class)

#change class
indices_pvtwNA[,1] <- as.Date(as.character(indices_pvtwNA[,1]))

#FiveYearsBack
#(head(trading_dates))
#(tail(trading_dates))

#kind of ridiculous to check sp500 for trading days, but I think the pvt is done now for merging with beta calculations later
indices_pvt_complete<-merge.data.frame(x=trading_dates[,"Date",drop=F],y=data.frame(indices_pvtwNA),by='Date',all.x=T)
indices_pvt_complete<-na_interpolation(indices_pvt_complete,options=LINEAR)
rownames(indices_pvt_complete) <- indices_pvt_complete$Date

indices_Returns <- CalculateReturns(indices_pvt_complete[,c(-1),drop=FALSE])

extract_Dates_indices_Returns <- data.frame(rownames(indices_Returns))
colnames(extract_Dates_indices_Returns) <- "Dates"
extract_Dates_indices_Returns[,1] <- as.Date(paste(extract_Dates_indices_Returns$Date), "%Y-%m-%d")
indices_Returns <- cbind(extract_Dates_indices_Returns,indices_Returns)

#filter out SP500TR extra dates which are used for Beta calculations
symbol_data_set <- rbind(symbol_data_set,subset(indices_DF, Date>= as.Date(first.date) & Date<= as.Date(last.date))[,,drop=FALSE])
symbol_data_set <- rbind(etf_and_crypto_DF,symbol_data_set)

#View(SP500TR[SP500TR$Date >= paste0(first.date)])
#pivot
symbol_data_set_pvtwNA <- reshape2::dcast(symbol_data_set, Date ~ Symbol,value.var='Adjusted',fun.aggregate = mean, fill=NULL)

#bind with trading days

eod_pvt_complete<-merge.data.frame(x=filtered_trading_dates[,"Date",drop=F],y=symbol_data_set_pvtwNA,by='Date',all.x=T)
#required for CalculateReturns
rownames(eod_pvt_complete) <- eod_pvt_complete$Date

#dailyReturns <- periodReturn(eod_pvt_complete[,c(-1),drop=FALSE],period='daily')

#filter bad data
md.pattern(eod_pvt_complete)

eod_pvt_complete <- eod_pvt_complete[colSums(is.na(eod_pvt_complete)) < (nrow(eod_pvt_complete)*.5)]

#done after join with FRED_Factors

FRED_factors_DF_pvt <- reshape2::dcast(FRED_factors_DF, Date ~ Symbol,value.var='Price',fun.aggregate = mean, fill=NULL)
#should clean up NA's just prior to fwrite
#should have more than 1 distinct value
FRED_factors_DF_pvt <- FRED_factors_DF_pvt[colSums(!is.na(FRED_factors_DF_pvt)) > 1]

#FRED_factors_DF_pvt["POPTOTUSA647NWDB"]
#bind with trading days
#View(FRED_factors_DF_pvt)

#can't join with trading dates until AFTER I fill in NA's
FRED_factors_DF_pvt <- na_interpolation(FRED_factors_DF_pvt, option = "linear")

FRED_factors_DF_pvt<-merge.data.frame(x=filtered_trading_dates[,"Date",drop=F],y=FRED_factors_DF_pvt,by='Date',all.x=T)
rownames(FRED_factors_DF_pvt) <- filtered_trading_dates$Date

md.pattern(FRED_factors_DF_pvt)

#only need 1 date
superSet_pvt <- cbind(FRED_factors_DF_pvt,eod_pvt_complete[,-1])

#fix for BTC breaking partial least squares regression& sp500
#https://stackoverflow.com/questions/39670918/replace-characters-in-column-names-gsub
names(superSet_pvt) <- gsub(x = names(superSet_pvt), pattern = "\\=", replacement = ".") 
names(superSet_pvt) <- gsub(x = names(superSet_pvt), pattern = "\\^", replacement = ".") 

rownames(superSet_pvt) <- superSet_pvt$Date

#View(superSet_pvt)

#superSet_pvt["VTWO"]

superSet_pvt <- na_interpolation(superSet_pvt, option = "linear")

#creates quarterlyData and weeklyData dataframe's for smaller analysis
source("weeklyQuarterly.R")

#cross validation
#5 months wasn't enough for 94 days (9 months trading days /2 -1, for some reason 87 lags was too much by 4... so I added 7 94-87=7 + short by 4 is 11, so 1 month is 21 trading days more)
validation_start <- first.date + months(6)
validation_end <- first.date+months(12)
#training_start <- first.date
#training_start <- first.date + months(9)
#cross correlations, vif reduction
training_start <- first.date + months(12)
training_end <- first.date+months(18)
#training_end <- first.date+months(12)
#forecasts
test_start <- first.date+months(18)
test_end <- first.date+months(19)
#27 is upper

#used by ccfreport.R and models.R
training_superSet_pvt_sub <- subset(superSet_pvt, rownames(superSet_pvt) >= training_start & rownames(superSet_pvt) <= training_end)

#used in ccfReport and models.R
#get non lagged numeric indexed list of dates from subsample
rowDateNums <- data.frame(superSet_pvt[,1])[,,drop=FALSE]
colnames(rowDateNums) <- "Date"
#just stocks

#temporarily reduce
yset <- colnames(training_superSet_pvt_sub[liststocksNoDups])

#fix rle's
tSize <- nrow(training_superSet_pvt_sub)

#remove Runs
yset <- unlist(mclapply(yset,function(x)
{
  is.rle <- rle(unlist(training_superSet_pvt_sub[x]))
  if(!max(is.rle$lengths)>=(tSize*.5))
  {
    return(x)
  }
}))

FREDlist <- sort(c(sort(etf_and_Crypto_list),FRED_Indicators,Indexes))
xset <- colnames(training_superSet_pvt_sub[FREDlist[FREDlist %in% colnames(superSet_pvt)]])
names(xset) <- xset
#Begin CCF
source("ccfReport.R")
#End CCF

#TTR
listOHCLVStocks <- group_split(na.omit(symbol_data_set[ which(symbol_data_set$Symbol %in% c(liststocksNoDups)),] %>% group_by(Symbol))) %>% setNames(liststocksNoDups)

#apply to only stocks for now, mixing up eth[erium] with Ethan stocks, will also save me the hassle of having to deal with RPL

#really TTR interactions
source("stock_interactions.R")

#used in cv.R
validation_superSet_pvt_sub <- subset(superSet_pvt, rownames(superSet_pvt) >= validation_start & rownames(superSet_pvt) <= validation_end)

#used in cv.R
test_sub <- subset(superSet_pvt, rownames(superSet_pvt) >= test_start & rownames(superSet_pvt) <= test_end)

if(download==TRUE)
  #45 minute for 188 symbols
{
  source("models.R")
  saveRDS(file="models.obj",models)
}
#models <- readRDS(file="modelsFullTTR.obj")
models <- readRDS(file="models.obj")

#http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata
#save workspace
save.image(file = "my_work_space.RData")
load("my_work_space.RData")


#creates bestModels object
if(download==TRUE)
  #52 minutes for 188 symbols
{
  source("cv.R")
  saveRDS(file="bestmodels.obj",bestmodels)
}

bestModels <- readRDS(file="bestmodels.obj",bestModels)

mean(unlist(abs(tail(CalculateReturns(models$AFTY$model$model[,1]),-1))))
bestModels$AFTY

acf(diff(quarterlyPriceDF[,1],1),lag.max = 53)

nrow(weeklyPriceDF)

#drop date column
eod_ret <- CalculateReturns(eod_pvt_complete[,c(-1),drop=FALSE])

extract_Dates_eod_ret <- data.frame(rownames(eod_ret))
colnames(extract_Dates_eod_ret) <- "Dates"
extract_Dates_eod_ret[,1] <- as.Date(paste(extract_Dates_eod_ret$Date), "%Y-%m-%d")
eod_ret <- cbind(extract_Dates_eod_ret,eod_ret)
#remove the first row
eod_ret <- tail(eod_ret,-1) #use tail with a negative value
#remove the last row
eod_ret <- head(eod_ret,-1) #use tail with a negative value

#filter out bad daily returns (over 300%)
max_daily_ret<-colMax(eod_ret)
selected_symbols_daily <- names(max_daily_ret)[which(max_daily_ret<=3)]

#needs to be done before pvt because interpolation for rarely reported ETF's will mess with this
sequential_repeat_closes <- apply(eod_ret, 2, function(x) max(rle(x)$lengths))
norepeats <- names(sequential_repeat_closes[sequential_repeat_closes<=30])

selected_symbols_daily <- selected_symbols_daily[selected_symbols_daily %in% norepeats]

#bypass filter (expect to chart outliers)
#selected_symbols_daily <- colnames(eod_ret)

#eod_ret <- subset(eod_ret[,c(selected_symbols_daily)], Date>= as.Date(first.date) & Date<= as.Date(first.date+months()))[,,drop=FALSE]

#create 9 months training dates
extract_Dates_eod_ret <- data.frame(rownames(eod_ret))
colnames(extract_Dates_eod_ret) <- "Dates"
extract_Dates_eod_ret[,1] <- as.Date(paste(extract_Dates_eod_ret$Date), "%Y-%m-%d")
training_eod_ret_dates <- subset(extract_Dates_eod_ret, Dates >= training_start & Dates <= training_end)
training_eod_ret_dates[,1] <- as.Date(paste(training_eod_ret_dates$Dates), "%Y-%m-%d")

print(paste("Training:",training_start, "to", training_end))

training_eod_ret <- eod_ret[as.character(training_eod_ret_dates[,]),]

eod_cum_ret_Training <- t(Return.cumulative(training_eod_ret[,c(selected_symbols_daily)]))

#create 9 months prior validation
validation_eod_ret_dates <- subset(extract_Dates_eod_ret, Dates >= validation_start & Dates <= validation_end)
validation_eod_ret_dates[,1] <- as.Date(paste(validation_eod_ret_dates$Dates), "%Y-%m-%d")

validation_eod_ret <- eod_ret[as.character(validation_eod_ret_dates[,]),]

#validation_filter_short (those that are below median Return for period that are also an outlier for being low during training)

eod_cum_ret_Validation <- t(Return.cumulative(validation_eod_ret[,c(selected_symbols_daily)]))

#print(paste("Validation:",validation_start, "to", validation_end))

#create 3 months test partition
test_eod_ret_dates <- subset(extract_Dates_eod_ret, Dates >= test_start & Dates <= test_end)
test_eod_ret_dates[,1] <- as.Date(paste(test_eod_ret_dates$Dates), "%Y-%m-%d")

test_eod_ret <- eod_ret[as.character(test_eod_ret_dates[,]),]

eod_cum_ret_Test <- t(Return.cumulative(test_eod_ret[,c(selected_symbols_daily)]))

#order cumulative returns
#https://stackoverflow.com/questions/13156448/how-can-i-sort-a-data-frame-with-only-one-column-without-losing-rownames
train_sorted_cum_returns <- eod_cum_ret_Training[order(-eod_cum_ret_Training[,1]), , drop = FALSE]
validation_sorted_cum_returns <- eod_cum_ret_Validation[order(-eod_cum_ret_Training[,1]), , drop = FALSE]
test_sorted_cum_returns <- eod_cum_ret_Test[order(-eod_cum_ret_Training[,1]), , drop = FALSE]

print(paste("Test:",test_start, "to", test_end))

#train_sorted_cum_returns

#outlier's
#http://r-statistics.co/Outlier-Treatment-With-R.html
train_outlier_values <- boxplot.stats(train_sorted_cum_returns)$out
train_medianReturn <- median(train_sorted_cum_returns)
hist(train_sorted_cum_returns, breaks = "sturges", xlim = c(-3, 3))

hist(train_sorted_cum_returns[train_sorted_cum_returns >= round(quantile(train_sorted_cum_returns, c(.02)),0) & train_sorted_cum_returns < round(quantile(train_sorted_cum_returns, c(.98)),0)], breaks= seq(-1, 1, 0.1))

validation_medianReturn <- median(validation_sorted_cum_returns)
test_medianReturn <- median(test_sorted_cum_returns)

train_picks <- names(train_sorted_cum_returns[which(sapply(train_sorted_cum_returns, function(x) x %in% train_outlier_values)),])

train_picks_returns <- t(eod_cum_ret_Training)[,train_picks]

train_short_picks <- train_picks_returns[train_picks_returns < train_medianReturn]
train_long_picks <- train_picks_returns[train_picks_returns > train_medianReturn]

train_picks_names <- rownames(data.frame(train_picks_returns))
train_short_picks_names <- rownames(data.frame(train_short_picks))
train_long_picks_names <- rownames(data.frame(train_long_picks))
#picks <- data.frame(train_sorted_cum_returns[train_sorted_cum_returns >= .5,])[,,drop=FALSE]

#sort(colnames(eod_ret))

#check if validation period matches training period median expectations, less stringent than outlier's
validation_long_picks <- validation_sorted_cum_returns[train_long_picks_names,]
validation_long_picks <- validation_long_picks[validation_long_picks > validation_medianReturn]
validation_long_picks_names <- rownames(data.frame(validation_long_picks))

validation_short_picks <- validation_sorted_cum_returns[train_short_picks_names,]
validation_short_picks <- validation_short_picks[validation_long_picks < validation_medianReturn]
validation_short_picks_names <- rownames(data.frame(validation_short_picks))

validation_picks_names <- c(validation_short_picks_names,validation_long_picks_names)

train_filter_short <- c(train_short_picks_names,"X.SP500TR")
train_filter_long <- c(train_long_picks_names,"X.SP500TR")

par(mfrow=c(2,2))
layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))

chart.CumReturns(training_eod_ret[c(train_filter_short)], legend.loc = 'topleft')
chart.CumReturns(training_eod_ret[c(train_filter_long)], legend.loc = 'topleft')

#chart.CumReturns(test_eod_ret[c(train_filter_short)], legend.loc = 'topleft')
#chart.CumReturns(test_eod_ret[c(train_filter_long)], legend.loc = 'topleft')

#try(chart.CumReturns(validation_eod_ret[c(train_filter_short)], legend.loc = 'topleft'),silent = TRUE)
#try(chart.CumReturns(validation_eod_ret[c(train_filter_long)], legend.loc = 'topleft'),silent = TRUE)
#could also try validation_filter_short & long
#try(chart.CumReturns(test_eod_ret[c(train_filter_short)], legend.loc = 'topleft'),silent = TRUE)
#try(chart.CumReturns(test_eod_ret[c(train_filter_long)], legend.loc = 'topleft'),silent = TRUE)

write.csv(eod_ret[,c(train_picks_names)],"returns_training_picks.csv")

#try to get financial statement data
#test <- Quandl(paste0("ZEE/",train_filter_long[1]), trim_start=training_start, trim_end=training_end)
#Quandl("ZEE/AAPL",trim_start=training_start, trim_end=training_end)

#https://www.r-bloggers.com/zacks-data-on-quandl/
#requires subscription
#Quandl("ZES/HPQ", trim_start="2011-11-21", trim_end="2014-08-20")[,1:6]

chart.CumReturns(indices_Returns[,-1], legend.loc = 'topleft')
plot(x=FRED_factors_DF_pvt$Date,y=FRED_factors_DF_pvt$NFCI)
plot(x=FRED_factors_DF_pvt$Date,y=FRED_factors_DF_pvt$TEDRATE)
plot(x=FRED_factors_DF_pvt$Date,y=FRED_factors_DF_pvt$VIXCLS)

#source("tradingStrategy2.R")
#supposed API CAll
#test <- wget("https://www.quandl.com/api/v3/datatables/ZACKS/EE.csv?ticker=AAPL&per_type=Q&per_end_date.gte=2017-01-01&per_end_date.lte=2018-12-31&qopts.columns=per_end_date,eps_mean_est&api_key=QgfDPCzvVmkDub4QqjQs")

#Test <- Quandl.datatable("ZACKS/FC", ticker="AAPL")
#Test$price
#View(Test)

#filter(eod_cum_ret_9Month_Training > mean(eod_cum_ret_9Month_Training, na.rm = TRUE))

#selected <- rownames(data.frame(top_picks))
#eod_ret[,selected]

#acf(training_eod_ret[4],lag.max=254)

#test <- as.xts(training_eod_ret)

#to.quarterly(training_eod_ret)

#Betas <- mclapply(validation_picks_names,derive_Betas)
#names(Betas) <- validation_picks_names

dev.off(dev.list()["RStudioGD"])		
par(mfrow=c(2,2))
layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
#autocorrelations
lapply(names(train_long_picks), function (x)
{
  acf(training_eod_ret[names(train_long_picks[x])],lag.max = NULL)
})


'
  mclapply(Betas, function (x)
  {
    print(paste(names(x), "Alpha: ", round(x[[1]][[1]],3), "Beta: ", round(x[[1]][[2]],3), "1st Date: ", x[[2]]))
  })
  '
#}
